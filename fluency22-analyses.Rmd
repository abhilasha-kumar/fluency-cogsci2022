---
title: "fluency22_project"
output: html_document
---

# Libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyboot)
library(ggplot2)
library(ggthemes)
library(broom)
library(lme4)
library(lmerTest)

```

This Rmd file contains the script for analyzing the fluency data. We first analyze the behavioral patterns and then compare the different foraging models.

# Drive Download

First we download the precomputed behavioral data from google drive.

```{r}

fluency_data = read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", '1-0jRnKqXm-BHojltAZhPmZNFR8Bu1xqj')) %>% filter(domain == "animals")

View(fluency_data %>% select(response, participant_designated_switch, simdrop, troyer,
                             norm_phon, word2vec_similarity))

```

# table 1 plot

```{r}
t1plot = fluency_data[1650:1653,] %>% 
  select(response_number, response, norm_phon, word2vec_similarity) %>% 
  rename(phonological = norm_phon, semantic = word2vec_similarity)%>%
  mutate(response_number = factor(1:4))%>%
  pivot_longer(names_to = "similarity", cols =phonological:semantic )%>%
  mutate(similarity = fct_relevel(similarity, "semantic", "phonological"))%>%
  rename(`retrieval order` = response_number)

t1plot %>%
  ggplot(aes(x = `retrieval order`, y = value, group = similarity, color = similarity)) +
  geom_line(size = 1)+
  geom_point(size = 10)+
  geom_label(aes(label = response), label.size = NA, 
             nudge_x = -.30, nudge_y = .03, size = 12)+
  labs(y = "similarity")+
  theme_classic()+
  scale_color_calc()+
    coord_cartesian(ylim=c(-0.01,0.7))+
   theme(axis.title = element_text(size = rel(2)),
          legend.position = "none",
         plot.title = element_text(hjust = .5),
         axis.line = element_line( size = 0.2),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(1)))

```

# Descriptives

```{r}
## num items produced

fluency_data %>% 
  group_by(dataset, domain, subject) %>%
  summarise(items = n()) %>%
  group_by(dataset) %>%
  summarise(mean_items = mean(items),
            sd_items = sd(items))

## mean similarities
fluency_data %>% filter(norm_phon != -999 & norm_phon !=1) %>%
  filter(response_number > 1)%>%
  group_by(dataset) %>%
  summarise(mean_sem = mean(word2vec_similarity, na.rm = TRUE),
            sd_sem = sd(word2vec_similarity, na.rm = TRUE),
            mean_phon = mean(norm_phon, na.rm = TRUE),
            sd_phon = sd(norm_phon, na.rm = TRUE))

## correlation

x = fluency_data %>%  filter(norm_phon != -999 & norm_phon !=1)
Hmisc::rcorr(x$norm_phon, x$word2vec_similarity)

```


# Retrieval order

```{r}

## combine semantic + phonological in one plot

order_data = fluency_data %>% filter(norm_phon != -999 & norm_phon !=1) %>%
  group_by(domain,response_number) %>%
  summarise_at(vars(norm_phon, word2vec_similarity), mean) %>%
  rename(phonological = norm_phon, semantic = word2vec_similarity)%>%
  pivot_longer(names_to = "similarity", cols =phonological:semantic )%>%
  mutate(similarity = fct_relevel(similarity, "semantic", "phonological"))%>%
  rename(`retrieval order` = response_number)

  order_data %>%
  ggplot(aes(x = `retrieval order`, y = value, group = similarity, color = similarity)) +
  geom_point(alpha = 0.2)+
  geom_smooth(method = "lm")+
  labs(y = "similarity")+
  theme_few()+
    facet_wrap(~domain)+
  scale_color_calc()+
    #theme(aspect.ratio = 1)+
   theme(axis.title = element_text(size = rel(2)),
          legend.title = element_text(face = "bold", size = rel(2)),
         legend.text  = element_text(size = rel(2)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(1)))

## lm

order_model_data = fluency_data %>% filter(norm_phon != -999 & norm_phon !=1) %>%
  select(subject, domain, response_number, norm_phon, word2vec_similarity) %>%
  rename(phonological = norm_phon, semantic = word2vec_similarity)%>%
  pivot_longer(names_to = "similarity", cols =phonological:semantic )%>%
  mutate(similarity = fct_relevel(similarity, "semantic", "phonological"))

ordermodel = lmer(data = order_model_data, 
     value ~ response_number*similarity + 
                                    (response_number*similarity|subject),
              control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4),
                                 optimizer = "bobyqa"))
summary(ordermodel)
```

# Num Items vs. Phon

```{r}
## data
items_produced = fluency_data %>% 
  group_by(dataset, domain, subject) %>%
  summarise(items = n()) %>%
  left_join( fluency_data %>% filter(response_number > 1) %>%
  group_by(dataset, domain, subject) %>% 
    summarise_at(vars(norm_phon, word2vec_similarity), mean, na.rm = TRUE))%>%
  # rescale phonological similarity
  mutate(norm_phon = norm_phon + 0.3) %>%
  rename(phonological = norm_phon, semantic = word2vec_similarity)%>%
  pivot_longer(names_to = "similarity", cols =phonological:semantic )%>%
  mutate(similarity = fct_relevel(similarity, "semantic", "phonological")) 

## plot
items_produced %>%
  ggplot(aes(x= value, y = items, color = similarity, group = similarity)) +
  geom_point(alpha = 0.2)+
geom_smooth(method = "lm")+
  theme_few()+
  facet_wrap(~domain)+
  labs(x = "similarity")+
  scale_color_calc()+
  #theme(aspect.ratio = 1)+
  theme(axis.title = element_text(size = rel(2)),
          legend.title = element_text(face = "bold", size = rel(2)),
         legend.text  = element_text(size = rel(2)),
         plot.title = element_text(hjust = .5),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(1)))
## model

## unscale phon similarity for model

items_produced = items_produced %>% 
  mutate(value = ifelse(similarity == "phonological", value - 0.3, value))

itemmodel = lmer(data = items_produced, 
     value ~ items*similarity + (1|subject),
              control=lmerControl(check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4),
                                 optimizer = "bobyqa"))
summary(itemmodel)
```

# Switch models
```{r}
x = fluency_data %>% filter(norm_phon != -999 & norm_phon !=1)%>%
  filter(dataset== "LEA") 

Hmisc::rcorr(x$participant_designated_switch, x$troyer)
Hmisc::rcorr(x$participant_designated_switch, x$simdrop)
## plots
switchplotdata = fluency_data %>% filter(norm_phon != -999 & norm_phon !=1) %>%
  filter(dataset== "LEA") %>%
  select(dataset, domain, subject, norm_phon, word2vec_similarity,
         participant_designated_switch,simdrop, troyer) %>%
  pivot_longer(names_to = "switch_method", 
               cols = c("simdrop", "participant_designated_switch", "troyer"))%>%
  filter(!is.na(value))%>%
  group_by(dataset,domain, subject, switch_method, value) %>%
  summarise_at(vars(norm_phon, word2vec_similarity), mean, na.rm = TRUE)%>% 
  rename(switch = value) %>%
  #mutate(norm_phon = norm_phon + 0.3)%>%
  pivot_longer(names_to = "similarity", cols = norm_phon:word2vec_similarity) %>%
  mutate(designation = ifelse(switch==0, "cluster", "switch"),
         `switch method` = fct_recode(switch_method,
                                    `participant\ndesignated` = "participant_designated_switch",
                                    `similarity\ndrop` = "simdrop",
                                    `Troyer\nnorms` = "troyer"),
         similarity= fct_recode(similarity, `phonological similarity` = "norm_phon",
                                `semantic similarity` = "word2vec_similarity"),
         similarity = fct_relevel(similarity, "semantic similarity", "phonological similarity"),
         `switch method` = fct_relevel(`switch method`, "Troyer\nnorms", "similarity\ndrop",
                                       "participant\ndesignated"))

scaleFUN <- function(x) sprintf("%.2f", x)

## barplot
semplot = switchplotdata  %>% filter(dataset == "LEA") %>%
  filter(similarity == "semantic similarity") %>%
   group_by(`switch method`, designation, similarity) %>%
summarise(ci = list(mean_cl_boot(value) %>% 
                        rename(mean=y, lwr=ymin, upr=ymax))) %>% unnest %>%
  ggplot(aes(x=`switch method` , y = mean,
             color = designation, fill = designation)) +
           geom_bar(stat = "identity", position = "dodge", width = 0.7, color= "black")+
        geom_errorbar(aes(ymin=lwr, ymax=upr), size = 0.5, width=.1,
                color = "black", position = position_dodge(0.75))+
  theme_few()+
  scale_fill_few()+
  labs(x ="", y = "mean\nsimilarity", title = "semantic similarity")+
  scale_y_continuous(labels=scaleFUN)+
  #theme(aspect.ratio = 1)+
   theme(axis.title = element_text(size = rel(2.5)),
          legend.title = element_text(face = "bold", size = rel(2.5)),
         legend.text  = element_text(size = rel(2.5)),
         plot.title = element_text(hjust = .5, size = rel(3)),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(2.5)))

phonplot = switchplotdata  %>% filter(dataset == "LEA") %>%
  filter(similarity != "semantic similarity") %>%
   group_by(`switch method`, designation, similarity) %>%
summarise(ci = list(mean_cl_boot(value) %>% 
                        rename(mean=y, lwr=ymin, upr=ymax))) %>% unnest %>%
  ggplot(aes(x=`switch method` , y = mean,
             color = designation, fill = designation)) +
           geom_bar(stat = "identity", position = "dodge", width = 0.7, color= "black")+
        geom_errorbar(aes(ymin=lwr, ymax=upr), size = 0.5, width=.1,
                color = "black", position = position_dodge(0.75))+
  scale_y_continuous(labels=scaleFUN)+
  theme_few()+
  scale_fill_few()+
  labs(x ="\nswitch method", y = "mean\nsimilarity", title = "phonological similarity")+
  #theme(aspect.ratio = 1)+
   theme(axis.title = element_text(size = rel(2.5)),
          legend.title = element_text(face = "bold", size = rel(2.5)),
         legend.text  = element_text(size = rel(2.5)),
         plot.title = element_text(hjust = .5, size = rel(3)),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(2.5)))

gridExtra::grid.arrange(semplot, phonplot, nrow = 2)

## model

switchmodel_data = fluency_data %>% filter(norm_phon != -999 & norm_phon !=1) %>%
  filter(dataset == "LEA") %>%
  select(dataset, domain,  subject,response, norm_phon, word2vec_similarity,
         participant_designated_switch,simdrop, troyer) %>%
  pivot_longer(names_to = "switch_method", 
               cols = c("simdrop", "participant_designated_switch", "troyer"))%>%
  filter(!is.na(value)) %>%
  rename(switch = value) %>%
  pivot_longer(names_to = "similarity", cols = norm_phon:word2vec_similarity) %>%
  mutate(designation = ifelse(switch==0, "cluster", "switch"),
         `switch method` = fct_recode(switch_method,
                                    `participant designated` = "participant_designated_switch",
                                    `similarity drop` = "simdrop",
                                    `Troyer norms` = "troyer"),
         similarity= fct_recode(similarity, phonological = "norm_phon",
                                semantic = "word2vec_similarity"),
         similarity = fct_relevel(similarity, "semantic", "phonological"))

switchmodel = lmer(data = switchmodel_data,
  value ~ similarity*designation*switch_method + 
                                    (1|subject),REML = FALSE, 
          control = lmerControl(optimizer="optimx",
            check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4),
                            optCtrl=list(method='nlminb')))

summary(switchmodel)

View(fluency_data %>% select(subject, response, participant_designated_switch, simdrop, troyer,
                             norm_phon, word2vec_similarity))

```

## cluster switch figures

```{r}
fig = fluency_data[c(793:797, 210:214),]%>% 
  mutate(troyer  = ifelse(row_number() == 1, 0,troyer),
         participant_designated_switch  = ifelse(row_number() == 1,
                                                 0,participant_designated_switch),
         simdrop  = ifelse(row_number() == 1, 0,simdrop)) %>%
  select(response_number, response, norm_phon, word2vec_similarity, 
         participant_designated_switch, troyer, simdrop) %>% 
  rename(phonological = norm_phon, semantic = word2vec_similarity,
         participant = participant_designated_switch,
         Troyer = troyer, `similarity-drop` = simdrop)%>%
  mutate(response_number = rep(factor(1:5), 2),
         subject = c(rep(1,5), rep(2,5)))%>%
  pivot_longer(names_to = "similarity", cols =phonological:semantic )%>%
  mutate(similarity = fct_relevel(similarity, "semantic", "phonological"),
         Troyer = fct_recode(factor(Troyer), cluster = "0", switch = "1"),
         `similarity-drop` = fct_recode(factor(`similarity-drop`), cluster = "0", switch = "1"),
         participant = fct_recode(factor(participant), cluster = "0", switch = "1"),)%>%
  rename(`retrieval order` = response_number)

fig1 = fig %>% filter(subject == 2) %>%
  ggplot(aes(x = `retrieval order`, y = value, group = similarity)) +
  geom_line(aes(linetype = similarity),size = 1)+
  geom_label(aes(label = response),label.size = NA, 
             nudge_x = -.35, nudge_y = .01, size = 12)+
  labs(y = "similarity", x = "")+
  geom_vline(xintercept = 4, color = "goldenrod", linetype = "dashed")+
  geom_vline(xintercept = 5, color = "springgreen3", linetype = "dashed")+
    geom_point(data = fig %>% filter(subject == 2 & !response %in% c("raccoon", "pig")),
      size = 10, color = "skyblue3")+
  geom_point(data = fig %>% filter(subject == 2 & response %in% c("raccoon")), 
               size = 10, color = "goldenrod", shape = 15)+
    geom_point(data = fig %>% filter(subject == 2 & response %in% c("pig")), 
               size = 10, fill = "springgreen3",shape = 23, color = "springgreen3")+
  #  annotate("text", x = 5.32, y = 0.45, label = "participant\nswitch", 
  #           size = 10, color = "springgreen3")+
  # annotate("text", x = 4.25, y = 0.45, label = "model\nswitch", 
  #          size = 10, color = "goldenrod")+
    theme_classic()+
  scale_color_colorblind()+
  scale_shape_manual(values=c(19, 15))+
   theme(axis.title = element_text(size = rel(2)),
         legend.title = element_text(face = "bold", hjust = .5, size = rel(2.5)),
         legend.text  = element_text(size = rel(2.5)),
         plot.title = element_text(face = "bold", hjust = .5, size = rel(2.5)),
         axis.line = element_line( size = 0.2),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(1)))


fig2 = fig %>% filter(subject == 1) %>%
  ggplot(aes(x = `retrieval order`, y = value, group = similarity)) +
  geom_line(aes(linetype = similarity),size = 1)+
  geom_label(aes(label = response),label.size = NA, 
             nudge_x = -.35, nudge_y = .01, size = 12)+
  labs(y = "similarity", x = "retrieval order")+
  geom_vline(xintercept = 4, color = "goldenrod", linetype = "dashed")+
  geom_vline(xintercept = 5, color = "springgreen3", linetype = "dashed")+
    geom_point(data = fig %>% filter(subject == 1 & !response %in% c("dolphin", "lizard")),
      size = 10, color = "skyblue3")+
  geom_point(data = fig %>% filter(subject == 1 & response %in% c("dolphin")), 
               size = 10, color = "goldenrod",shape = 15)+
  geom_point(data = fig %>% filter(subject == 1 & response %in% c("lizard")), 
               size = 10, fill = "springgreen3",shape = 23, color = "springgreen3")+
  #  annotate("text", x = 5.3, y = 0.57, label = "participant\nswitch", 
  #           size = 10, color = "springgreen3")+
  # annotate("text", x = 4.25, y = 0.57, label = "model\nswitch", 
  #          size = 10, color = "goldenrod")+
    theme_classic()+
  scale_color_colorblind()+
  scale_shape_manual(values=c(19, 15))+
   theme(axis.title = element_text(size = rel(2)),
         legend.title = element_text(face = "bold", hjust = .5, size = rel(2.5)),
         legend.text  = element_text(size = rel(2.5)),
         plot.title = element_text(face = "bold", hjust = .5, size = rel(2.5)),
         axis.line = element_line( size = 0.2),
         strip.text.x = element_text(size = rel(2.5)),
         axis.text.x = element_text(size = rel(1)))

gridExtra::grid.arrange(fig1, fig2, nrow = 2)
```


# Foraging Models

Here, we first download the foraging models fit at the particpant level.

```{r}

fluency_data_fits <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", '1djZ8XlGfl-d-tpAJVvJxqiToEQdLmwBd'))

data_labels = readxl::read_excel("data_fluency_cogsci2022.xlsx") %>% 
  select(subject, dataset) %>% distinct()

fluency_data_fits = left_join(fluency_data_fits, data_labels)

## exclude participant designated for these
errors = fluency_data_fits %>% select(-starts_with("errors_participant"))%>%
  select(dataset, subject, number_of_items, starts_with("errors")) %>%
  pivot_longer(names_to = "model", 
               cols = errors_static_optimal:errors_troyer_pglobaldynamic_random) %>%
  separate(model, into = c("errors", "norms", "type", "errortype")) %>% select(-errors)%>%
  mutate(errortype = ifelse(is.na(errortype), type, errortype),
         type = ifelse(type %in% c("optimal", "random"), norms,type),
    LL = -value)
```
## calculate delta BIC

In this method, a BIC is calculated separately for each subject based on the number of items they produced, and then the median BIC is calculated from the difference of optimal and random models
```{r}
hills_bic = errors %>%
  mutate(k = ifelse(type %in% c("static", "dynamic"), 2, 3),
                  BIC = k*log(number_of_items) - 2*(LL))%>%
  select(-c(value,LL,k) )%>%
  pivot_wider(names_from = errortype, values_from = BIC)%>%
  mutate(deltaBIC  = random - optimal) %>%
  group_by(norms, type) %>%
  summarise(medianBIC = median(deltaBIC)) %>%
  arrange(norms, desc(medianBIC))
```


## test model differences

```{r}
modeltestdata = errors %>% filter(errortype == "optimal") %>%
  mutate(k = ifelse(type %in% c("static", "dynamic"), 2, 3),
                  BIC = k*log(number_of_items) - 2*(LL))

## troyer models
troyer = modeltestdata %>% filter(norms != "simdrop" & 
                                    type %in% c("plocaldynamic", "pglobaldynamic"))
summary(lmer(data = troyer, 
                 BIC ~ type + (1|subject)))


## simdrop models
simdrop = modeltestdata %>% filter(norms != "troyer"& 
                                     type %in% c("plocaldynamic", "pglobaldynamic"))
simdrop$type = as.factor(simdrop$type)
simdrop_bic_model = lmer(data = simdrop, 
                 BIC ~ type + (1|subject))
summary(simdrop_bic_model)

```

# participant-designated

```{r}
participant_errors = fluency_data_fits %>% 
  select(dataset, subject, number_of_items, starts_with("errors_participant")) %>%
  filter(dataset == "LEA") %>%
  pivot_longer(names_to = "model", 
        cols = errors_participant_dynamic_optimal:errors_participant_pglobaldynamic_random) %>%
  separate(model, into = c("errors", "norms", "type", "errortype")) %>% select(-errors)%>%
  mutate(errortype = ifelse(is.na(errortype), type, errortype),
         type = ifelse(type %in% c("optimal", "random"), norms,type),
    LL = -value)

participant_bic = participant_errors %>%
  mutate(k = ifelse(type %in% c("static", "dynamic"), 2, 3),
                  BIC = k*log(number_of_items) - 2*(LL))%>%
  select(-c(value,LL,k) )%>%
  pivot_wider(names_from = errortype, values_from = BIC)%>%
  mutate(deltaBIC  = random - optimal) %>%
  group_by(norms, type) %>%
  summarise(medianBIC = median(deltaBIC)) %>%
  arrange(norms, desc(medianBIC))

lea_testdata = participant_errors %>% filter(errortype == "optimal") %>%
  mutate(k = ifelse(type %in% c("static", "dynamic"), 2, 3),
                  BIC = k*log(number_of_items) - 2*(LL))
lea_testdata$type = as.factor(lea_testdata$type)
contrasts(lea_testdata$type) = contr.treatment(4, base = 4)
summary(lmer(data = lea_testdata, 
                 BIC ~ type + (1|subject)))
contrasts(lea_testdata$type)

lea_testdata %>%
  ggplot() + geom_histogram(aes(x = BIC, group = type, fill = type), alpha = 0.5, binwidth = 100)
```


# vocab

This section goes over how the list of animals used in the foraging models was created. Please refer to the Jupyter notebook for more details.

```{r}
data = readxl::read_excel("data_fluency_cogsci2022.xlsx")
simlabels = read.csv("similaritylabels.csv", header = FALSE)
vocab = as.data.frame(c(unique(data$response), unique(simlabels$V1)))
colnames(vocab) = c("vocab_word")
vocab = vocab %>% distinct()

write.csv(vocab, file = "vocab.csv", row.names = FALSE)

vocab = read_csv("vocab.csv")
animals = data %>% filter(domain == "animals") %>% select(response) %>%distinct()
animals = as.data.frame(c(animals$response, simlabels$V1))
colnames(animals) = c("animal_word")
animals = animals %>% distinct()

animals = animals %>% 
  mutate(in_vocab = ifelse(animal_word %in% vocab$vocab_word, 1, 0))

animals = animals %>% select(-in_vocab)
write.csv(animals, file = "new_animals.csv", row.names = FALSE, col.names = FALSE)

freqs = read_csv("animal_freqs.csv")
oldfreqs = read.csv("old_frequencies.csv", header = FALSE) %>% 
  rename(animal_word = V1, freq2 = V2)
animals = left_join(animals, freqs)
animals = left_join(animals, oldfreqs)

animals = animals %>% mutate(freq = ifelse(is.na(freq), log(freq2, base = 10), freq))
animals = animals%>% mutate(freq = ifelse(is.na(freq), 0.5, freq))
animals = animals %>% select(-freq2)
write.csv(animals, file = "animals_frequencies.csv", row.names = FALSE)
```












